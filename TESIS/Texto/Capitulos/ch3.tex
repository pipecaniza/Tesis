%% intro.tex

\chapter{Universo imperativo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Existen dos grandes modelos computacionales: el funcional, basado en el calculo lambda de Alonzo Church, y el imperativo, basado en la máquina de Turing, inventada por Alan Turing. La exploración de estos modelos no sólo hace parte de la teoría computacional, sino también, de lenguajes formales y compiladores, pues cada modelo de cómputo genera diferentes paradigmas que definen el lenguaje y su implementación.

\paragraph{El modelo computacional es indiferente,} tal como lo plante la tesis Church-Turing (CT)\footnote{La tesis CT no es un teorema.}, una máquina de Turing puede simular cualquier otro modelo computacional con máximo una ralentización polinomial, esto tiene como resultado que dada la clase de complejidad \textbf{P}  en el modelo análogo\footnote{Clase de complejidad P, conjunto de problemas solucionables en tiempo polinomial por una máquina determinista.}, esta no es más grande que en una máquina de Turing. Si la tesis es cierta, implicaría que la clase \textbf{P} definida por los alienígenas es igual a la nuestra. \cite{Arora2009}




\section{Funcional vs Imperativo}

Comúnmente tenemos la pre-concepción de que el universo Funcional es excluyente al Imperativo, en cierto sentido puede ser cierto, pues están basados en diferentes modelos computacionales, asumiendo que la tesis CT es cierta, sabemos que todo el conjunto de los problemas solucionables en cualquier modelo computacional determinista (válido) pueden ser solucionados con los dos enfoques, es decir, ambos modelos son igualmente poderosos, la pregunta que se podría hacer es, ¿existe alguna manera de comunicar ambos universos para aplicar técnicas existentes que solo se encuentran en alguno de los dos?

Actualmente todos los lenguajes de programación modernos mezclan atributos de ambos paradigmas creando a su vez nuevos paradigmas que dotan a los lenguajes de gran flexibilidad. Según \textsc{Beckman}, en el inicio de la computación moderna, el mundo se partió en dos campos, el campo \emph{bottom-up} teniendo como base las máquinas de Turing, empezando con el hardware y añadiendo abstracción a medida que sea necesario, cada vez acercándose mas a las matemáticas pero nunca perjudicando el performance, el otro campo \emph{top-down} parte de las matemáticas y cada vez quita abstracción para acercarse a la máquina sin importar el performance, comenzando desde el calculo lambda, actualmente se está llegando a un punto de equilibrio entre ambos campos \cite{Beckman2007}  . Esto es posible con la definición de un lenguaje que permita utilizar estructuras pertenecientes a cada uno de los enfoques computacionales, esto puede responder en cierta medida la pregunta anterior, pero ¿que sucede si el lenguaje no soporta todas las estructuras necesarias para realizar distintas técnicas que solo pertenecen a un enfoque?\\

La implementación de un lenguaje funcional en una máquina imperativa requiere de múltiples transformaciones y optimizaciones de bajo nivel, esto permite crear lenguajes funcionales con un desempeño aceptable, de no ser así, como resultado se tendría un lenguaje funcional con grandes fallas de desempeño.

Los compiladores más eficientes están escritos en C++, lenguaje multiparadigma (mayormente imperativo), que permite una buena capacidad de abstracción y no es lejano a la máquina, por lo cuál, en términos de performance, éste lenguaje es el más apropiado. El problema radica en que el universo funcional, es más cercano al problema de los compiladores, fácilmente se puede entender la anterior afirmación con la implementación de un front-end, el cuál es declarativo, son múltiples funciones interactuando, que retornan estructuras y realmente no importa mucho el concepto de estamento, la generación de estructuras recurrentes y pattern matching en lugar de estructuras complejas con punteros y switches.

Luego, no quiere decir que acercarse con un enfoque imperativo suponga una aproximación errada, mas bien, reduce la expresividad en el dominio del problema.\\

Una solución plausible podria ser crear un nuevo lenguaje $L^*$ que soporte ambos paradigmas, partiendo de éste escribir un compilador con las técnicas funcionales sin perder mucho performance, pero escribir el compilador para el lenguje $L^*$ sería demasiado complejo.

La programación funcional ofrece una visión de alto nivel de programación, provee una gran variedad de características que ayudan a construir librerías de funciones elegantes, poderosas y generales.\cite{Thompson2011}

	\subsection{Arquitectura Von-Neumann}
	La popularidad del modelo imperativo se debe a la arquitectura del computador que usamos, la arquitectura Von-Neumann, inventada por el matemático Húngaro-Estadounidense con el mismo nombre. Es fácil notar que aunque la máquina de Turing y el cálculo lambda son altamente abstractos, el primero está mucho mas cerca a una implementación real de un computador basado en la tecnología digital. La arquitectura Von-Neumann está más ligada al concepto de estamentos que modifiquen el estado de la máquina, que a la composición de funciones puras.\\\\
	
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
		\coordinate (ma) at (0,0);   
		\coordinate (mb) at (8,0);
		\coordinate (mc) at (8,1);
		\coordinate (md) at (0,1);   
		
		\coordinate (ca) at (0,-1);
		\coordinate (cb) at (3,-1);
		\coordinate (cc) at	(3,-4);
		\coordinate (cd) at (0,-4);
		
		\coordinate (aa) at (4,-1);
		\coordinate (ab) at (8,-1);
		\coordinate (ac) at	(8,-4);
		\coordinate (ad) at (4,-4);		
		
		% Memoria
		\draw (ma) -- (mb) node [above=2mm, midway] {\textsc{memoria}};
		\draw (mb) -- (mc);
		\draw (mc) -- (md);
		\draw (md) -- (ma); 
		
		% Unidad de control
		\draw (ca) -- (cb) node [below=6mm, midway] {\begin{tabular}{c}
			\textsc{Unidad}\\\textsc{de}\\\textsc{control}
		\end{tabular}};
		\draw (cb) -- (cc);
		\draw (cc) -- (cd);
		\draw (cd) -- (ca);
		
		% Memoria
		\draw (aa) -- (ab) node [below=2mm, midway] (ALU) {\begin{tabular}{c}
			\textsc{Unidad}\\\textsc{logica}\\\textsc{aritmética}
		\end{tabular}};
		\draw (ab) -- (ac);
		\draw (ac) -- (ad);
		\draw (ad) -- (aa);    
		
		\node [below=0.1mm of ALU] [box] (ac) {acumulador};
		\node [below left=8mm and 0.1mm of ac] [box] (i) {Entrada};
		\node [below right=8mm and 0.1mm of ac] [box] (o) {Salida};
		
		
		\end{tikzpicture}
		
		\caption{Arquitectura Von-Neumann}
		\label{figram}
	\end{figure}
	
	Todos los computadores digitales están basados en ésta arquitectura; la pregunta que podría surgir es ¿como los computadores pueden ejecutar código funcional?. Partimos de que la solución algorítmica de un problema es distinta en el modelo funcional e imperativo, pero en ambos se puede solucionar el problema. Así pues, si se construyera una máquina basada en una arquitectura funcional, ésta debe entender un lenguaje máquina muy abstracto basado en el cálculo lambda. Llámese $M^f$ a ésta máquina funcional, ésta no debe entender código imperativo, al igual que una máquina imperativa no entiende código funcional, así pues, debe existir una forma de representar el código funcional en imperativo y viceversa partiendo de la \emph{tesis CT}, pues ambos modelos parecen ser análogos.
	
	Lo anterior permite responder a la posibilidad de escribir código funcional en una máquina imperativa, al fin y al cabo, cualquier código terminará siendo código imperativo de bajo nivel entendido por el computador, ésta labor es realizada por el \emph{compilador}. Si careciéramos de la teoría de compiladores no sería plausible la utilización de cualquier tipo de programación funcional. En términos generales, la utilización de la programación funcional en una máquina imperativa no es más que una ilusión, es decir, es sólo la expresividad del lenguaje, pues el compilador es el encargado de transformar de alguna forma dicho código a una representación imperativa.
	
	Resulta bastante difuso lograr separar y representar los dos modelos computacionales desde éste punto, tan sólo se puede afirmar que uno esta basado en la máquina de Turing y el otro en el cálculo lambda, y dado que una solución en un modelo puede ser reducida o representada como el otro, se puede reafirmar su naturaleza análoga. Pero más allá de ésto es difícil definir la interacción y estructura de cada uno, partiendo desde los compiladores sólo podrían definirse como paradigmas, que incluso se pueden mezclar en un lenguaje pues al final serán traducidos a una representación genérica. 
	
	
\section{Parser imperativo clásico}
El análisis sintáctico o parsing está presente en todos los compiladores, puesto que es la fase que se encarga de evaluar el programa fuente verificando que éste cumpla con las especificaciones del lenguaje definido para el compilador \cite{MarioZ}, ademas, realiza la representación intermedia que será utilizada por el \emph{back-end} para optimizar y generar código \cite{Dragon}.

Existen múltiples formas de diseñar un parser, pero la más común es la forma \emph{descendente}, puede verse como el problema de construir un árbol de análisis sintáctico para la cadena de entrada, partiendo desde la raíz y creando los nodos del árbol de análisis sintáctico en preorden.\cite{Dragon}

Así pues, si se quisiera construir un parser descendente por la izquierda se deben crear tantas funciones como no terminales existan, y en cada una se verifica si la estructura interna de la regla es correcta o no.

\begin{exmp}
	Sea $G_1$ una gramática válida sobre el lenguaje $L'$, y $G_1 \in LL(1)$.
	Donde $G_1$ está definido por:
		
	\begin{lstlisting}
	FUNCTION -> 'function' '(' PARAMS ')'
	PARAMS   ->  var ',' PARAMS | E
	\end{lstlisting}
	
	$G_1$ no es una gramática recursiva por la izquierda y tampoco es ambigua.
	
	Así se construirá un parser descendente por la izquierda imperativo clásico:
	\begin{lstlisting}[language=C++, caption="Parser imperativo"]
	void FUNCTION()
	{
		if(current_token == token.function){
			if(current_token == '('){
				PARAMS();
				if(current_token != ')')
					cout << "ERROR\n";
			}
			else
				cout << "ERROR\n";
		}
		else{
			cout << "ERROR\n";
		}
	}
	
	void PARAMS()
	{
		if(current_token == token.var){
			if(current_token == ','){
				PARAMS();
			}
		}
	}
	\end{lstlisting}
\end{exmp}

	Como se puede observar un parser imperativo clásico se vuelve rápidamente inmanejable, por ésta razón existen generadores de analizadores sintácticos, pero éstos últimos tienen un gran problema, que generan una enorme cantidad de código a espaldas del programador.
	
	A simple vista se puede observar la gran desventaja que tiene esta forma de implementar los analizadores sintácticos, están totalmente desligados de la gramática, y teniendo en cuenta que aún no se han implementado las estructuras para crear el árbol de sintaxis abstracta, omitiendo el análisis léxico y la definición de los tokens y la demás estructura presente en la clase que contiene el parser.


\section{Parser Funcional sobre un lenguaje imperativo}

La necesidad de crear un parser elegante y sencillo en el universo imperativo es obvia. Ya se ha descrito los componentes esenciales y los recursos que debe proveer el lenguaje para que los \emph{Parser Combinators} puedan ser implementados. Al comprar el parser imperativo con el funcional se encuentra una abismal diferencia, y marcan como claro ganador a los  \emph{Parser Combinators}. Partiendo de los mecanismos de abstracción de \emph{C++} descritos en el primer capítulo se podría desarrollar una librería básica que intente simular los ya mencionados parsers funcionales.




El anterior \emph{Parser Combinator} sobre un lenguaje imperativo no es más que un prototípo inicial, se pueden observar que muchas de las operaciones aún se tienen que hacer de forma manual, ésto debido a que para poder transportar toda una librería funcional al universo imperativo requiere de grandes transformaciones y diseños no triviales. A partir de éste punto se deja una hipótesis no demostrada, pues requiere de un análisis profundo de la basta teoría de \emph{mónadas} en el paradigma funcional.

\begin{conj}
	monada
\end{conj}

